{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to SubKube Developers. Here you will find all relevant information to deploy your application on SubKube.","title":"Home"},{"location":"cli/","text":"SubKube offers a simple CLI tool to interact with your SubKube Projects and Namespaces, called subctl . Installation The subctl is written in python, using click, and as such is easiest installed using pip as shown below, but self-contained binaries are available for most platforms as well. 1 pip install git+https://github.com/subkube/subctl Usage 1 2 3 4 5 6 7 8 9 10 subctl login subctl get project subctl get namespace subctl use project subctl use namespace subctl create namespace subctl create project","title":"subctl"},{"location":"cli/#installation","text":"The subctl is written in python, using click, and as such is easiest installed using pip as shown below, but self-contained binaries are available for most platforms as well. 1 pip install git+https://github.com/subkube/subctl","title":"Installation"},{"location":"cli/#usage","text":"1 2 3 4 5 6 7 8 9 10 subctl login subctl get project subctl get namespace subctl use project subctl use namespace subctl create namespace subctl create project","title":"Usage"},{"location":"getting_started/","text":"Getting Started Tip For hardcore command line users, we've created subctl , a simple CLI tool allowing you to log in to SubKube and interact with your Projects and Namespace directly from your shell, just as you would with kubectl . More about how to install subctl here Signing up To start using SubKube, sign up for an account Before you can start creating projects, you'll need to setup a billing method !!!+ tip If you wish to use subctl , don't forget to log in 1 subctl login Create a Project Once you've signed up and are logged in to SubKube, you need to create a project to deploy Namespaces and Workloads to. Subkube UI Open the Projects page and click the Create Project button. subctl 1 subctl create project <PROJECT-NAME> Create a Namespace After creating a project, we need to create a Kubernetes Namespace to deploy our Workloads to. Subkube UI This can easily be done from a Project page, by clicking the Create Namespace button. subctl 1 subctl create namespace <NAMESPACE-NAME> -p <PROJECT-UUID> Setup Kubectl In order to use kubectl , we need to setup our kubeconfig . Subkube UI On your projects' page you will find the Kubeconfig card, which allows you to download the kubeconfig as a file, which will be called subkubeconfig , or you can show the kubeconfig for inspection or manual copy-pasting / distribution. subctl 1 subctl use project <project-uuid> Deploy workloads Once we have our project, namespace and kubectl configured, we can check to see if everything works by running a test pod interactively. As you can notice - we've set a securityContext using overrides, please see Concept: Workloads for more on SecurityContext and PodSecurityPolicies in Subkube - we've set limits for the pod using --limits, please see Concept: Projects for more on Resource Limits in Subkube 1 2 3 kubectl run -n <YOUR-NAMESPACE> -i --tty busybox --image = busybox \\ --overrides = '{\"spec\":{\"securityContext\":{\"runAsUser\":65534}}}' \\ --limits = 'cpu=100m,memory=100Mi' --rm -- echo 'Hello World from Subkube!'","title":"Getting Started"},{"location":"getting_started/#getting-started","text":"Tip For hardcore command line users, we've created subctl , a simple CLI tool allowing you to log in to SubKube and interact with your Projects and Namespace directly from your shell, just as you would with kubectl . More about how to install subctl here","title":"Getting Started"},{"location":"getting_started/#signing-up","text":"To start using SubKube, sign up for an account Before you can start creating projects, you'll need to setup a billing method !!!+ tip If you wish to use subctl , don't forget to log in 1 subctl login","title":"Signing up"},{"location":"getting_started/#create-a-project","text":"Once you've signed up and are logged in to SubKube, you need to create a project to deploy Namespaces and Workloads to. Subkube UI Open the Projects page and click the Create Project button. subctl 1 subctl create project <PROJECT-NAME>","title":"Create a Project"},{"location":"getting_started/#create-a-namespace","text":"After creating a project, we need to create a Kubernetes Namespace to deploy our Workloads to. Subkube UI This can easily be done from a Project page, by clicking the Create Namespace button. subctl 1 subctl create namespace <NAMESPACE-NAME> -p <PROJECT-UUID>","title":"Create a Namespace"},{"location":"getting_started/#setup-kubectl","text":"In order to use kubectl , we need to setup our kubeconfig . Subkube UI On your projects' page you will find the Kubeconfig card, which allows you to download the kubeconfig as a file, which will be called subkubeconfig , or you can show the kubeconfig for inspection or manual copy-pasting / distribution. subctl 1 subctl use project <project-uuid>","title":"Setup Kubectl"},{"location":"getting_started/#deploy-workloads","text":"Once we have our project, namespace and kubectl configured, we can check to see if everything works by running a test pod interactively. As you can notice - we've set a securityContext using overrides, please see Concept: Workloads for more on SecurityContext and PodSecurityPolicies in Subkube - we've set limits for the pod using --limits, please see Concept: Projects for more on Resource Limits in Subkube 1 2 3 kubectl run -n <YOUR-NAMESPACE> -i --tty busybox --image = busybox \\ --overrides = '{\"spec\":{\"securityContext\":{\"runAsUser\":65534}}}' \\ --limits = 'cpu=100m,memory=100Mi' --rm -- echo 'Hello World from Subkube!'","title":"Deploy workloads"},{"location":"soon/","text":"Note Coming soon!","title":"Reference"},{"location":"api/authentication/","text":"How to authenticate with SubKube API Basic Authentication Tokens","title":"Authentication"},{"location":"api/authentication/#basic-authentication","text":"","title":"Basic Authentication"},{"location":"api/authentication/#tokens","text":"","title":"Tokens"},{"location":"api/reference/","text":"Resource API Path Projects https://api.subku.be/projects.json Project Namespaces https://api.subku.be/projects/.../namespaces.json","title":"Reference"},{"location":"concepts/project/","text":"Project In SubKube, your Kubernetes Namespaces are organised inside a Project. Project can be personal, or belong to an Organization. Namespaces Namespaces are used in Kubernetes to group Workloads together. Namespaces can operate in various levels of isolation. In SubKube, this is configurable per project. More about namespaces can be found in the Kubernetes docs Resource Quota Resource Quota are set on namespaces by Rancher based on the set Project limits. More about Resource Quotas in the Rancher (on which Subkube is built) docs Billing At Subkube, you are charged for reservation resources as specified by the limits of a project. These limits can be changed on the fly. Each hour, we calculate the total of resource limits for a certain resource type during that hour, and charge that to your subscription. If you change the limits for a project, or delete a project within that hour period, you're subscription will be charged for the applicable part of the hour, multiplied by the resource limit. Persistent Volumes Are available and can be created using normal PVC's. Storage is implemented using Longhorn CSI. More about Persistent Volumes and associated Claims can be found in the Kubernetes docs Ingress In Kubernetes, Ingress objects are used to allow your application to be accessed by the outside world, by using a reverse proxy. You can read more about the Ingress concept in the Kubernetes docs The Nginx Ingress Controller is available for all users of Subkube, including certmanager, to allow SSL certificates to be set up automatically using Let's Encrypt. The Nginx Ingress Controller allows for very flexible configuration, for a full list of all options please see the nginx-ingress docs","title":"Project"},{"location":"concepts/project/#project","text":"In SubKube, your Kubernetes Namespaces are organised inside a Project. Project can be personal, or belong to an Organization.","title":"Project"},{"location":"concepts/project/#namespaces","text":"Namespaces are used in Kubernetes to group Workloads together. Namespaces can operate in various levels of isolation. In SubKube, this is configurable per project. More about namespaces can be found in the Kubernetes docs","title":"Namespaces"},{"location":"concepts/project/#resource-quota","text":"Resource Quota are set on namespaces by Rancher based on the set Project limits. More about Resource Quotas in the Rancher (on which Subkube is built) docs","title":"Resource Quota"},{"location":"concepts/project/#billing","text":"At Subkube, you are charged for reservation resources as specified by the limits of a project. These limits can be changed on the fly. Each hour, we calculate the total of resource limits for a certain resource type during that hour, and charge that to your subscription. If you change the limits for a project, or delete a project within that hour period, you're subscription will be charged for the applicable part of the hour, multiplied by the resource limit.","title":"Billing"},{"location":"concepts/project/#persistent-volumes","text":"Are available and can be created using normal PVC's. Storage is implemented using Longhorn CSI. More about Persistent Volumes and associated Claims can be found in the Kubernetes docs","title":"Persistent Volumes"},{"location":"concepts/project/#ingress","text":"In Kubernetes, Ingress objects are used to allow your application to be accessed by the outside world, by using a reverse proxy. You can read more about the Ingress concept in the Kubernetes docs The Nginx Ingress Controller is available for all users of Subkube, including certmanager, to allow SSL certificates to be set up automatically using Let's Encrypt. The Nginx Ingress Controller allows for very flexible configuration, for a full list of all options please see the nginx-ingress docs","title":"Ingress"},{"location":"concepts/workloads/","text":"Workloads In Kubernetes, you run your application as a workload . There are various ways to orchestrate workloads, for instance using the deployment resource, the statefulSet or the daemonSet resource. Many apps consist of various different workloads, which need to work together in order to serve the application as a whole. Kubernetes has an applicable workload type for any of these. For more information on workloads, please checkout the dedicated Kubernetes docs Pod Security Context By default, many containers used to run as root user. This isn't an option on a shared cluster, as this could potentially allow users to \"break out\" of a running container, and gain access to the entire node. In Kubernetes this is enforced using PodSecurityPolicies. The default PodSecurityPolicy enforced on Subkube is called 'restricted' and is very comparable to those seen in large scale enterprise Kubernetes deployments. Not Available in Subkube Resource Reason Daemonset DaemonSets can not be used on SubKube as it is a shared platform, where no application should need a DaemonSet. NodePort Service Too unpredictable for production usage , incompatible with Subkube cluster firewall Container Hostport Too unpredictable for production usage , incompatible with Subkube cluster firewall Custom Resource Incompatible with shared cluster usage, as CRDs are Definition cluster-wide resources.","title":"Workloads"},{"location":"concepts/workloads/#workloads","text":"In Kubernetes, you run your application as a workload . There are various ways to orchestrate workloads, for instance using the deployment resource, the statefulSet or the daemonSet resource. Many apps consist of various different workloads, which need to work together in order to serve the application as a whole. Kubernetes has an applicable workload type for any of these. For more information on workloads, please checkout the dedicated Kubernetes docs","title":"Workloads"},{"location":"concepts/workloads/#pod-security-context","text":"By default, many containers used to run as root user. This isn't an option on a shared cluster, as this could potentially allow users to \"break out\" of a running container, and gain access to the entire node. In Kubernetes this is enforced using PodSecurityPolicies. The default PodSecurityPolicy enforced on Subkube is called 'restricted' and is very comparable to those seen in large scale enterprise Kubernetes deployments.","title":"Pod Security Context"},{"location":"concepts/workloads/#not-available-in-subkube","text":"Resource Reason Daemonset DaemonSets can not be used on SubKube as it is a shared platform, where no application should need a DaemonSet. NodePort Service Too unpredictable for production usage , incompatible with Subkube cluster firewall Container Hostport Too unpredictable for production usage , incompatible with Subkube cluster firewall Custom Resource Incompatible with shared cluster usage, as CRDs are Definition cluster-wide resources.","title":"Not Available in Subkube"},{"location":"guides/pod-security-context/","text":"As Subkube is a shared platform, containers are only allowed to run in so-called 'restricted' PodSecurityPolicies. This guide walks through the steps of creating a deployment, seeing it fail, updating it to use a SecurityContext, and seeing it run successfully. Prerequisites A Namespace in a Subkube Project Kubectl Steps Setting up a basic Deployment For this example, we will use the echoserver image, which sets up a simple HTTP server which replies everything sent to it. deployment-before.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 apiVersion : apps/v1 kind : Deployment metadata : creationTimestamp : null labels : app : hello-subkube name : hello-subkube spec : replicas : 1 selector : matchLabels : app : hello-subkube strategy : {} template : metadata : creationTimestamp : null labels : app : hello-subkube spec : containers : - image : ealen/echo-server:latest name : echoserver resources : {} status : {} Let's apply the supplied, unmodified deployment, to a namespace, called demo in our example: 1 kubectl apply -n demo -f deployment-before.yaml Initial testing Because we don't want to set up any Services or an Ingress, we'll use a PortForward to connect to the Deployment: 1 2 > kubectl port-forward -n demo deployment/hello-subkube 8080 :8080 error: unable to forward port because pod is not running. Current status = Pending \ud83d\ude15 Figuring out why our Pod fails Let's check the logs and see what is going wrong 1 2 > kubectl logs deployment/hello-subkube -n demo Error from server ( BadRequest ) : container \"echoserver\" in pod \"hello-subkube-758bc95559-bgg29\" is waiting to start: CreateContainerConfigError We are shown a CreateContainerConfigError while trying to fetch the Pod's logs. Let's look in to that: 1 2 3 4 5 6 > kubectl describe pods -n demo ... Normal Pulled 47s ( x8 over 2m18s ) kubelet, minikube-local-local Successfully pulled image \"ealen/echo-server:latest\" Warning Failed 47s ( x8 over 2m18s ) kubelet, minikube-local-local Error: container has runAsNonRoot and image will run as root Normal Pulling 33s ( x9 over 2m27s ) kubelet, minikube-local-local Pulling image \"ealen/echo-server:latest\" ... Because we haven't configured our Deployment to run with an appopriate SecurityContext, the Kubernets control plane isn't allowing Pods in our Deployment to run. Setting a SecurityContext We can easily fix this by setting a SecurityContext . For many containers this is as easy as setting the runAsUser property to the value 65534 , which translates to the nobody user account. By default, the echo-server image runs on port 80 , but because our container won't be running as root , the container will be unable to allocate the port, and the Pod will fail. Instead, we want to run the echo-server on a different port, say 8080. Let's update our Deployment manifest accordingly: deployment-after.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 apiVersion : apps/v1 kind : Deployment metadata : creationTimestamp : null labels : app : hello-subkube name : hello-subkube spec : replicas : 1 selector : matchLabels : app : hello-subkube strategy : {} template : metadata : creationTimestamp : null labels : app : hello-subkube spec : containers : - image : ealen/echo-server:latest name : echoserver env : - name : PORT value : \"8080\" securityContext : runAsUser : 65534 status : {} Now we should apply the modified deployment: 1 kubectl apply -n demo -f deployment-after.yaml Testing our revised Deployment Let's again try to start our PortForward: 1 kubectl port-forward -n demo deployment/hello-subkube 8080 :8080 That should've worked. Now we can use curl to test our Deployment: 1 2 > curl 'localhost:8080/?echo_body=All_Good' All_Good More Resources & Further Reading K8s Concepts: Pod Security Policies K8s Concepts: Pod Security Standards Better Programming on Medium: Secure Your Kubernetes Cluster With Pod Security Policies","title":"Configure a Pod to run with a limited SecurityContext"},{"location":"guides/pod-security-context/#prerequisites","text":"A Namespace in a Subkube Project Kubectl","title":"Prerequisites"},{"location":"guides/pod-security-context/#steps","text":"","title":"Steps"},{"location":"guides/pod-security-context/#setting-up-a-basic-deployment","text":"For this example, we will use the echoserver image, which sets up a simple HTTP server which replies everything sent to it. deployment-before.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 apiVersion : apps/v1 kind : Deployment metadata : creationTimestamp : null labels : app : hello-subkube name : hello-subkube spec : replicas : 1 selector : matchLabels : app : hello-subkube strategy : {} template : metadata : creationTimestamp : null labels : app : hello-subkube spec : containers : - image : ealen/echo-server:latest name : echoserver resources : {} status : {} Let's apply the supplied, unmodified deployment, to a namespace, called demo in our example: 1 kubectl apply -n demo -f deployment-before.yaml","title":"Setting up a basic Deployment"},{"location":"guides/pod-security-context/#initial-testing","text":"Because we don't want to set up any Services or an Ingress, we'll use a PortForward to connect to the Deployment: 1 2 > kubectl port-forward -n demo deployment/hello-subkube 8080 :8080 error: unable to forward port because pod is not running. Current status = Pending \ud83d\ude15","title":"Initial testing"},{"location":"guides/pod-security-context/#figuring-out-why-our-pod-fails","text":"Let's check the logs and see what is going wrong 1 2 > kubectl logs deployment/hello-subkube -n demo Error from server ( BadRequest ) : container \"echoserver\" in pod \"hello-subkube-758bc95559-bgg29\" is waiting to start: CreateContainerConfigError We are shown a CreateContainerConfigError while trying to fetch the Pod's logs. Let's look in to that: 1 2 3 4 5 6 > kubectl describe pods -n demo ... Normal Pulled 47s ( x8 over 2m18s ) kubelet, minikube-local-local Successfully pulled image \"ealen/echo-server:latest\" Warning Failed 47s ( x8 over 2m18s ) kubelet, minikube-local-local Error: container has runAsNonRoot and image will run as root Normal Pulling 33s ( x9 over 2m27s ) kubelet, minikube-local-local Pulling image \"ealen/echo-server:latest\" ... Because we haven't configured our Deployment to run with an appopriate SecurityContext, the Kubernets control plane isn't allowing Pods in our Deployment to run.","title":"Figuring out why our Pod fails"},{"location":"guides/pod-security-context/#setting-a-securitycontext","text":"We can easily fix this by setting a SecurityContext . For many containers this is as easy as setting the runAsUser property to the value 65534 , which translates to the nobody user account. By default, the echo-server image runs on port 80 , but because our container won't be running as root , the container will be unable to allocate the port, and the Pod will fail. Instead, we want to run the echo-server on a different port, say 8080. Let's update our Deployment manifest accordingly: deployment-after.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 apiVersion : apps/v1 kind : Deployment metadata : creationTimestamp : null labels : app : hello-subkube name : hello-subkube spec : replicas : 1 selector : matchLabels : app : hello-subkube strategy : {} template : metadata : creationTimestamp : null labels : app : hello-subkube spec : containers : - image : ealen/echo-server:latest name : echoserver env : - name : PORT value : \"8080\" securityContext : runAsUser : 65534 status : {} Now we should apply the modified deployment: 1 kubectl apply -n demo -f deployment-after.yaml","title":"Setting a SecurityContext"},{"location":"guides/pod-security-context/#testing-our-revised-deployment","text":"Let's again try to start our PortForward: 1 kubectl port-forward -n demo deployment/hello-subkube 8080 :8080 That should've worked. Now we can use curl to test our Deployment: 1 2 > curl 'localhost:8080/?echo_body=All_Good' All_Good","title":"Testing our revised Deployment"},{"location":"guides/pod-security-context/#more-resources-further-reading","text":"K8s Concepts: Pod Security Policies K8s Concepts: Pod Security Standards Better Programming on Medium: Secure Your Kubernetes Cluster With Pod Security Policies","title":"More Resources &amp; Further Reading"},{"location":"guides/soon/","text":"Note Coming soon!","title":"Volumes on SubKube"}]}